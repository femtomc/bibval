@article{lew_probabilistic_2023,
	title = {Probabilistic Programming with Stochastic Probabilities},
	journal = {Proc. {ACM} Program. Lang.},
	volume = {7},
	number = {{PLDI}},
	pages = {1708--1732},
	year = {2023},
	url = {https://dl.acm.org/doi/10.1145/3591290},
	doi = {10.1145/3591290},
	author = {Lew, Alexander K. and Ghavamizadeh, Matin and Rinard, Martin C. and Mansinghka, Vikash K.},
}

@misc{lim2025optimisingdensitycomputationsprobabilistic,
      title={Optimising Density Computations in Probabilistic Programs via Automatic Loop Vectorisation},
      author={Sangho Lim and Hyoungjin Lim and Wonyeol Lee and Xavier Rival and Hongseok Yang},
      year={2025},
      eprint = {2511.11070},
      doi = {10.48550/arXiv.2511.11070},
      archivePrefix={arXiv},
      primaryClass={cs.PL},
      url={https://arxiv.org/abs/2511.11070},
}

@inproceedings{gonzalez2011parallel,
  author       = {Joseph Gonzalez and Yucheng Low and Arthur Gretton and Carlos Guestrin},
  title        = {Parallel Gibbs Sampling: From Colored Fields to Thin Junction Trees},
  booktitle    = {{AISTATS}},
  series       = {{JMLR} Proceedings},
  volume       = {15},
  pages        = {324--332},
  publisher    = {JMLR.org},
  address      = {Fort Lauderdale, FL, USA},
  year         = {2011},
  url          = {https://proceedings.mlr.press/v15/gonzalez11a.html},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{lew2023semantics,
	title = {Semantics of Probabilistic Program Traces},
	author = {Lew, Alexander K. and Sennesh, Eli and Van De Meent, Jan-Willem and Mansinghka, Vikash K.},
	booktitle = {LAFI 2023 at POPL},
	publisher = {ACM},
	address = {Boston, MA, USA},
	year = {2023},
	location = {Boston, MA},
	url = {https://popl23.sigplan.org/details/lafi-2023-papers/1/Semantics-of-Probabilistic-Program-Traces},

}

@misc{abadi_tensorflow_2016,
	title = {TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems},
	author = {Mart\'in Abadi and Ashish Agarwal and Paul Barham and Eugene Brevdo and Zhifeng Chen and Craig Citro and Greg S. Corrado and Andy Davis and Jeffrey Dean and Matthieu Devin and Sanjay Ghemawat and Ian Goodfellow and Andrew Harp and Geoffrey Irving and Michael Isard and Yangqing Jia and Rafal Jozefowicz and Lukasz Kaiser and Manjunath Kudlur and Josh Levenberg and Dan Man\'e and Rajat Monga and Sherry Moore and Derek Murray and Chris Olah and Mike Schuster and Jonathon Shlens and Benoit Steiner and Ilya Sutskever and Kunal Talwar and Paul Tucker and Vincent Vanhoucke and Vijay Vasudevan and Fernanda Vi\'egas and Oriol Vinyals and Pete Warden and Martin Wattenberg and Martin Wicke and Yuan Yu and Xiaoqiang Zheng},
	year = {2016},
	note = {Software available from tensorflow.org},
	url = {https://www.tensorflow.org/},
	doi = {10.48550/arXiv.1603.04467}
}

@article{bingham_pyro_2019,
	title = {Pyro: Deep Universal Probabilistic Programming},
	author = {Eli Bingham and Jonathan P. Chen and Martin Jankowiak and Fritz Obermeyer and Neeraj Pradhan and Theofanis Karaletsos and Rohit Singh and Paul Szerlip and Paul Horsfall and Noah D. Goodman},
	journal = {Journal of Machine Learning Research},
	volume = {20},
	number = {28},
	pages = {1--6},
	year = {2019},
	url = {https://jmlr.org/papers/v20/18-403.html},
	doi = {10.48550/arXiv.1810.09538}
}

@article{carpenter_stan_2017,
	title = {Stan: A Probabilistic Programming Language},
	author = {Bob Carpenter and Andrew Gelman and Matthew D. Hoffman and Daniel Lee and Ben Goodrich and Michael Betancourt and Marcus Brubaker and Jiqiang Guo and Peter Li and Allen Riddell},
	journal = {Journal of Statistical Software},
	volume = {76},
	number = {1},
	pages = {1--32},
	year = {2017},
	doi = {10.18637/jss.v076.i01}
}

@inproceedings{goodman2008church,
	title = {Church: a language for generative models},
	author = {Noah D. Goodman and Vikash K. Mansinghka and Daniel M. Roy and Keith Bonawitz and Joshua B. Tenenbaum},
	booktitle = {Proceedings of the 24th Conference on Uncertainty in Artificial Intelligence},
	pages = {220--229},
	publisher = {AUAI Press},
	address = {Corvallis, OR, USA},
	year = {2008},
	doi = {10.48550/arXiv.1206.3255}
}

@misc{goodman2014webppl,
	title = {The Design and Implementation of Probabilistic Programming Languages},
	author = {Noah D. Goodman and Andreas Stuhlm{\"u}ller},
	year = {2014},
	note = {electronic; retrieved 2024/6/20},
	url = {http://dippl.org}
}

@misc{frostig_compiling_2018,
	title = {Compiling machine learning programs via high-level tracing},
	author = {Roy Frostig and Matthew James Johnson and Chris Leary},
	year = {2018},
	journal = {Systems for Machine Learning},
	note = {SysML 2018}
}

@inproceedings{gothoskar2023bayes3d,
	title = {3DP3: 3D Scene Perception via Probabilistic Programming},
	author = {Nishad Gothoskar and Marco Cusumano-Towner and Ben Zinberg and Matin Ghavamizadeh and Falk Pollok and Austin Garrett and Joshua B. Tenenbaum and Dan Gutfreund and Vikash K. Mansinghka},
	booktitle = {Advances in Neural Information Processing Systems},
	volume = {36},
	publisher = {Curran Associates, Inc.},
	address = {New Orleans, LA, USA},
	year = {2023},

	doi = {10.48550/arXiv.2111.00312}
}

@inproceedings{gothoskar20233dnel,
	title = {3D Neural Embeddings Likelihood: Probabilistic Inverse Graphics for Robust 3D Reconstruction},
	author = {Nishad Gothoskar and Matin Ghavami and Eric Scharff and Miguel Jaquez and Austin Duguid and Stuart Russell and Dan Gutfreund and Vikash K. Mansinghka},
	booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
	pages = {8585--8594},
	publisher = {IEEE},
	address = {Paris, France},
	year = {2023},
	doi = {10.1109/ICCV51070.2023.00789}
}

@inproceedings{lew_pclean_2021,
	title = {PClean: Bayesian Data Cleaning at Scale with Domain-Specific Probabilistic Programming},
	author = {Alexander K. Lew and Monica Agrawal and David Sontag and Vikash K. Mansinghka},
	booktitle = {International Conference on Artificial Intelligence and Statistics},
	pages = {1927--1935},
	publisher = {PMLR},
	address = {Virtual Event},
	year = {2021},
	doi = {10.48550/arXiv.2007.11838}
}

@inproceedings{lew2023smcp3,
  author       = {Alexander K. Lew and George Matheos and Tan Zhi{-}Xuan and Matin Ghavamizadeh and Nishad Gothoskar and Stuart Russell and Vikash K. Mansinghka},
  editor       = {Francisco J. R. Ruiz and Jennifer G. Dy and Jan{-}Willem van de Meent},
  title        = {{SMCP3:} Sequential Monte Carlo with Probabilistic Program Proposals},
  booktitle    = {International Conference on Artificial Intelligence and Statistics, 25-27 April 2023, Palau de Congressos, Valencia, Spain},
  series       = {Proceedings of Machine Learning Research},
  volume       = {206},
  pages        = {7061--7088},
  publisher    = {{PMLR}},
  address      = {Valencia, Spain},
  year         = {2023},
  url          = {https://proceedings.mlr.press/v206/lew23a.html},
  biburl       = {https://dblp.org/rec/conf/aistats/LewMZGGRM23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{harris2020array,
	title = {Array programming with {NumPy}},
	author = {Charles R. Harris and K. Jarrod Millman and St{\'{e}}fan J. van der Walt and Ralf Gommers and Pauli Virtanen and David Cournapeau and Eric Wieser and Julian Taylor and Sebastian Berg and Nathaniel J. Smith and Robert Kern and Matti Picus and Stephan Hoyer and Marten H. van Kerkwijk and Matthew Brett and Allan Haldane and Jaime Fern{\'{a}}ndez del R{\'{i}}o and Mark Wiebe and Pearu Peterson and Pierre G{\'{e}}rard-Marchant and Kevin Sheppard and Tyler Reddy and Warren Weckesser and Hameer Abbasi and Christoph Gohlke and Travis E. Oliphant},
	journal = {Nature},
	volume = {585},
	number = {7825},
	pages = {357--362},
	year = {2020},
	doi = {10.1038/s41586-020-2649-2}
}

@article{blelloch1994implementation,
	title = {Implementation of a portable nested data-parallel language},
	author = {Guy E. Blelloch and Siddhartha Chatterjee and Jonathan C. Hardwick and Jay Sipelstein and Marco Zagha},
	journal = {Journal of Parallel and Distributed Computing},
	volume = {21},
	number = {1},
	pages = {4--14},
	year = {1994},
	doi = {10.1006/jpdc.1994.1031}
}

@inproceedings{borgstrom2016lambda,
	title = {A lambda-calculus foundation for universal probabilistic programming},
	author = {Johannes Borgstr{\"o}m and Ugo Dal Lago and Andrew D. Gordon and Marcin Szymczak},
	booktitle = {Proceedings of the 21st ACM SIGPLAN International Conference on Functional Programming},
	pages = {33--46},
	publisher = {ACM},
	address = {New York, NY, USA},
	year = {2016},
	doi = {10.1145/2951913.2951942}
}

@book{burke1996j,
	title = {The J programming language},
	author = {Kenneth E. Iverson and Roger K.W. Hui},
	publisher = {Iverson Software Inc.},
	address = {Toronto, Canada},
	year = {1996}
}

@inproceedings{cusumano-towner_gen_2019,
	title = {Gen: a general-purpose probabilistic programming system with programmable inference},
	author = {Marco F. Cusumano-Towner and Feras A. Saad and Alexander K. Lew and Vikash K. Mansinghka},
	booktitle = {Proceedings of the 40th ACM SIGPLAN Conference on Programming Language Design and Implementation},
	pages = {221--236},
	publisher = {ACM},
	address = {New York, NY, USA},
	year = {2019},
	doi = {10.1145/3314221.3314642}
}

@inproceedings{heunen2017convenient,
	title = {A convenient category for higher-order probability theory},
	author = {Chris Heunen and Ohad Kammar and Sam Staton and Hongseok Yang},
	booktitle = {2017 32nd Annual ACM/IEEE Symposium on Logic in Computer Science (LICS)},
	pages = {1--12},
	publisher = {IEEE},
	address = {Reykjavik, Iceland},
	year = {2017},
	doi = {10.1109/LICS.2017.8005137}
}

@inproceedings{huot2020correctness,
	title = {Correctness of automatic differentiation via diffeologies and categorical gluing},
	author = {Mathieu Huot and Sam Staton and Matthijs V{\'a}k{\'a}r},
	booktitle = {Foundations of Software Science and Computation Structures (FoSSaCS 2020)},
	series = {Lecture Notes in Computer Science},
	volume = {12077},
	pages = {319--338},
	year = {2020},
	publisher = {Springer},
    address = {Cham, Switzerland},
	doi = {10.1007/978-3-030-45231-5_17}
}

@book{iverson1962programming,
	title = {A programming language},
	author = {Kenneth E. Iverson},
	publisher = {John Wiley \& Sons},
	address = {New York, NY, USA},
	year = {1962}
}

@book{jones1993partial,
	title = {Partial evaluation and automatic program generation},
	author = {Neil D. Jones and Carsten K. Gomard and Peter Sestoft},
	publisher = {Prentice Hall},
	address = {Englewood Cliffs, NJ, USA},
	year = {1993}
}

@article{lew2020trace,
	title = {Trace types and denotational semantics for sound programmable inference in probabilistic languages},
	author = {Alexander K. Lew and Marco F. Cusumano-Towner and Benjamin Sherman and Michael Carbin and Vikash K. Mansinghka},
	journal = {Proc. {ACM} Program. Lang.},
	volume = {4},
	number = {{POPL}},
	pages = {19:1--19:32},
	year = {2020},
	doi = {10.1145/3371087}
}

@inproceedings{lunden_compiling_2022,
	title = {Compiling universal probabilistic programming languages with efficient parallel sequential Monte Carlo inference},
	author = {Daniel Lund{\'e}n and Joey {\"O}hman and Jan-Willem van de Meent and Fredrik Ronquist},
	booktitle = {European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases},
	pages = {1--17},
	publisher = {Springer},
	address = {Cham, Switzerland},
	year = {2022},
	doi = {10.1007/978-3-030-99336-8_2}
}

@article{mansinghka_probabilistic_2018,
	title = {Probabilistic programming with programmable inference},
	author = {Vikash K. Mansinghka and Ulrich Schaechtle and Shivam Handa and Alexey Radul and Yutian Chen and Martin Rinard},
	journal = {ACM SIGPLAN Notices},
	volume = {53},
	number = {4},
	pages = {603--616},
	year = {2018},
	doi = {10.1145/3296979.3192409}
}

@article{mansinghka_venture_2014,
	title = {Venture: a higher-order probabilistic programming platform with programmable inference},
	author = {Vikash Mansinghka and Daniel Selsam and Yura Perov},
	journal = {CoRR},
	volume = {abs/1404.0099},
	year = {2014},
	url = {http://arxiv.org/abs/1404.0099},
	eprint = {1404.0099},
	doi = {10.48550/arXiv.1404.0099},
	archivePrefix = {arXiv},
	primaryClass = {cs.AI},

}

@inproceedings{murray_automated_2018,
	title = {Automated variational inference for Gaussian process models},
	author = {Iain Murray and Ryan Adams},
	booktitle = {Advances in Neural Information Processing Systems},
	pages = {1404--1414},
	publisher = {Curran Associates, Inc.},
	address = {Montr{\'e}al, Canada},
	year = {2018}
}

@inproceedings{paszke_pytorch_2019,
  author       = {Adam Paszke and Sam Gross and Francisco Massa and Adam Lerer and James Bradbury and Gregory Chanan and Trevor Killeen and Zeming Lin and Natalia Gimelshein and Luca Antiga and Alban Desmaison and Andreas K{\"{o}}pf and Edward Z. Yang and Zachary DeVito and Martin Raison and Alykhan Tejani and Sasank Chilamkurthy and Benoit Steiner and Lu Fang and Junjie Bai and Soumith Chintala},
  editor       = {Hanna M. Wallach and Hugo Larochelle and Alina Beygelzimer and Florence d'Alch{\'{e}}{-}Buc and Emily B. Fox and Roman Garnett},
  title        = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
  booktitle    = {Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC, Canada},
  pages        = {8024--8035},
  publisher    = {Curran Associates, Inc.},
  address      = {Vancouver, BC, Canada},
  year         = {2019},
  url          = {https://proceedings.neurips.cc/paper/2019/hash/bdbca288fee7f92f2bfa9f7012727740-Abstract.html},
  bibsource    = {dblp computer science bibliography, https://dblp.org},
  doi          = {10.48550/arXiv.1912.01703}
}

@article{phan_composable_2019,
  author  = {Du Phan and Neeraj Pradhan and Martin Jankowiak},
  title   = {Composable Effects for Flexible and Accelerated Probabilistic Programming in NumPyro},
  journal = {CoRR},
  volume  = {abs/1912.11554},
  year    = {2019},
  url     = {http://arxiv.org/abs/1912.11554},
  eprint = {1912.11554},
  doi = {10.48550/arXiv.1912.11554},
  archivePrefix = {arXiv},
  primaryClass  = {cs.LG},

}

@inproceedings{saad2023timeseries,
    author = {Feras Saad and Brian Patton and Matthew Douglas Hoffman and Rif A. Saurous and Vikash Mansinghka},
    editor = {Andreas Krause and Emma Brunskill and Kyunghyun Cho and Barbara Engelhardt and Sivan Sabato and Jonathan Scarlett},
    title = {Sequential Monte Carlo Learning for Time Series Structure Discovery},
    booktitle = {International Conference on Machine Learning, {ICML} 2023, 23-29 July 2023, Honolulu, Hawaii, {USA}},
    series = {Proceedings of Machine Learning Research},
    volume = {202},
    pages = {29473--29489},
    publisher = {{PMLR}},
    address = {Honolulu, HI, USA},
    year = {2023},
    url = {https://proceedings.mlr.press/v202/saad23a.html}
}

@article{scibior2018denotational,
	title = {Denotational validation of higher-order Bayesian inference},
	author = {Adam {\v{S}}cibior and Ohad Kammar and Matthijs V{\'{a}}k{\'{a}}r and Sam Staton and Hongseok Yang and Yufei Cai and Klaus Ostermann and Sean K. Moss and Chris Heunen and Zoubin Ghahramani},
	journal = {Proceedings of the ACM on Programming Languages},
	volume = {2},
	number = {POPL},
	pages = {60:1--60:29},
	year = {2018},
	doi = {10.1145/3158148}
}

@inproceedings{taha1999multi,
	title = {Multi-stage programming: its theory and applications},
	author = {Walid Taha},
	booktitle = {Applied Semantics Summer School},
	pages = {145--174},
	year = {1999},
	publisher = {Springer},
    address = {Caminha, Portugal}
}

@article{tan2023BToMgoals,
	title = {Bayesian Theory of Mind: Modeling Joint Belief-Desire Attribution},
	author = {Melanie Tan and Tobias Gerstenberg and Noah D. Goodman and Judith E. Fan},
	journal = {Proceedings of the Annual Meeting of the Cognitive Science Society},
	volume = {45},

	year = {2023}
}

@inproceedings{tran_deep_2022,
    author = {Dustin Tran and Matthew D. Hoffman and Rif A. Saurous and Eugene Brevdo and Kevin Murphy and David M. Blei},
    title = {Deep Probabilistic Programming},
    booktitle = {5th International Conference on Learning Representations, {ICLR} 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings},
    publisher = {OpenReview.net},
    address = {Toulon, France},
    year = {2017},
    url = {https://openreview.net/forum?id=Hy6b4Pqee},

}

@article{wong2023PLoT,
	title = {From Word Models to World Models: Translating from Natural Language to the Probabilistic Language of Thought},
	author = {Lionel Wong and Gabriel Grand and Alexander K. Lew and Noah D. Goodman and Vikash K. Mansinghka and Jacob Andreas and Joshua B. Tenenbaum},
	journal = {CoRR},
	volume = {abs/2306.12672},
	year = {2023},
	doi = {10.48550/arXiv.2306.12672},
	url = {https://doi.org/10.48550/arXiv.2306.12672},
    eprint = {2306.12672},
    archivePrefix = {arXiv},
    primaryClass = {cs.CL},

}

@inproceedings{tristan_augur_2014,
	title = {Augur: Data-Parallel Probabilistic Modeling},
	author = {Jean-Baptiste Tristan and Daniel Huang and Joseph Tassarotti and Adam Craig Pocock and Stephen J. Green and Guy L. Steele Jr.},
	booktitle = {Advances in Neural Information Processing Systems 27 (NIPS 2014)},
	pages = {2600--2608},
	publisher = {Curran Associates, Inc.},
	address = {Montr{\'e}al, Canada},
	year = {2014},
	url = {https://proceedings.neurips.cc/paper/2014/hash/cf9a242b70f45317ffd281241fa66502-Abstract.html},
	doi = {10.48550/arXiv.1312.3613}
}

@article{tran2016edward,
	title = {Edward: A library for probabilistic modeling, inference, and criticism},
	author = {Dustin Tran and Alp Kucukelbir and Adji B. Dieng and Maja Rudolph and Dawen Liang and David M. Blei},
	journal = {CoRR},
	volume = {abs/1610.09787},
	year = {2016},
	url = {http://arxiv.org/abs/1610.09787},
	eprint = {1610.09787},
	doi = {10.48550/arXiv.1610.09787},
	archivePrefix = {arXiv},
	primaryClass = {stat.ML},

}

@article{wood_anglican_2017,
	title = {Design and Implementation of Probabilistic Programming Language Anglican},
	author = {Tolpin, David and van de Meent, Jan-Willem and Yang, Hongseok and Wood, Frank},
	journal = {ACM Transactions on Programming Languages and Systems},
	volume = {40},
	number = {4},
	pages = {1--46},
	year = {2017},
	doi = {10.1145/3064899}
}

@article{lew_adev_2023,
    title = {{ADEV}: {Sound} {Automatic} {Differentiation} of {Expected} {Values} of {Probabilistic} {Programs}},
    shorttitle = {{ADEV}},
    journal = {Proc. {ACM} Program. Lang.},
    volume = {7},
    number = {{POPL}},
    pages = {121--153},
    year = {2023},
    url = {https://dl.acm.org/doi/10.1145/3571198},
    doi = {10.1145/3571198},
    abstract = {Optimizing the expected values of probabilistic processes is a central problem in computer science and its applications, arising in fields ranging from artificial intelligence to operations research to statistical computing. Unfortunately, automatic differentiation techniques developed for deterministic programs do not in general compute the correct gradients needed for widely used solutions based on gradient-based optimization.  
In this paper, we present ADEV, an extension to forward-mode AD that correctly differentiates the expectations of probabilistic processes represented as programs that make random choices. Our algorithm is a source-to-source program transformation on an expressive, higher-order language for probabilistic computation, with both discrete and continuous probability distributions. The result of our transformation is a new probabilistic program, whose expected return value is the derivative of the original program’s expectation. This output program can be run to generate unbiased Monte Carlo estimates of the desired gradient, that can be used within the inner loop of stochastic gradient descent. We prove ADEV correct using logical relations over the denotations of the source and target probabilistic programs. Because it modularly extends forward-mode AD, our algorithm lends itself to a concise implementation strategy, which we exploit to develop a prototype in just a few dozen lines of Haskell (https://github.com/probcomp/adev).},
    author = {Lew, Alexander K. and Huot, Mathieu and Staton, Sam and Mansinghka, Vikash K.},
    month = jan
}

@article{becker_probabilistic_2024,
    title = {Probabilistic {Programming} with {Programmable} {Variational} {Inference}},
    journal = {Proc. {ACM} Program. Lang.},
    volume = {8},
    number = {{PLDI}},
    pages = {2123--2147},
    doi = {10.1145/3656463},
    url = {https://doi.org/10.1145/3656463},
    author = {Becker, McCoy R. and Lew, Alexander K. and Wang, Xiaoyan and Ghavami, Matin and Huot, Mathieu and Rinard, Martin C. and Mansinghka, Vikash K.},
    month = jun,
    year = {2024}
}

@article{gardner1970life,
    title = {The fantastic combinations of {J}ohn {C}onway's new solitaire game 'life'},
    author = {Gardner, Martin},
    journal = {Scientific American},
    volume = {223},
    number = {4},
    pages = {120--123},
    year = {1970}
}

@article{geman1984stochastic,
    title = {Stochastic relaxation, {G}ibbs distributions, and the {B}ayesian restoration of images},
    author = {Geman, Stuart and Geman, Donald},
    journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
    volume = {PAMI-6},
    number = {6},
    pages = {721--741},
    year = {1984},
    publisher = {IEEE},
    doi = {10.1109/TPAMI.1984.4767596}
}

@incollection{neal2011mcmc,
    title = {{MCMC} using {H}amiltonian dynamics},
    author = {Neal, Radford M},
    booktitle = {Handbook of {M}arkov chain {M}onte {C}arlo},
    editors = {Brooks, Steve and Gelman, Andrew and Jones, Galin L. and Meng, Xiao-Li},
    pages = {113--162},
    year = {2011},
    publisher = {Chapman and Hall/CRC},
    address = {Boca Raton, FL, USA},
    doi = {10.48550/arXiv.1206.1901}
}

@article{gordon1993novel,
    title = {Novel approach to nonlinear/non-{G}aussian {B}ayesian state estimation},
    author = {Gordon, N. J. and Salmond, D. J. and Smith, A. F. M.},
    journal = {IEE Proceedings F (Radar and Signal Processing)},
    volume = {140},
    number = {2},
    pages = {107--113},
    year = {1993},
    publisher = {IET},
    doi = {10.1049/ip-f-2.1993.0015}
}

@article{durrant2006simultaneous,
    title = {Simultaneous localization and mapping: part {I}},
    author = {Durrant-Whyte, Hugh and Bailey, Tim},
    journal = {IEEE Robotics \& Automation Magazine},
    volume = {13},
    number = {2},
    pages = {99--110},
    year = {2006},
    publisher = {IEEE},
    doi = {10.1109/MRA.2006.1638022}
}

@inproceedings{pharr2012ispc,
    title = {ispc: {A} {SPMD} compiler for high-performance {CPU} programming},
    author = {Pharr, Matt and Mark, William R},
    booktitle = {2012 Innovative Parallel Computing (InPar)},
    pages = {1--13},
    year = {2012},
    publisher = {IEEE},
    address = {San Jose, CA, USA},
    doi = {10.1109/InPar.2012.6339601}
}

@inproceedings{salmon_parallel_2011,
    address = {New York, NY, USA},
    series = {{SC} '11},
    title = {Parallel random numbers: as easy as 1, 2, 3},
    isbn = {978-1-4503-0771-0},
    shorttitle = {Parallel random numbers},
    url = {https://doi.org/10.1145/2063384.2063405},
    doi = {10.1145/2063384.2063405},
    abstract = {Most pseudorandom number generators (PRNGs) scale poorly to massively parallel high-performance computation because they are designed as sequentially dependent state transformations. We demonstrate that independent, keyed transformations of counters produce a large alternative class of PRNGs with excellent statistical properties (long period, no discernable structure or correlation). These counter-based PRNGs are ideally suited to modern multi-core CPUs, GPUs, clusters, and special-purpose hardware because they vectorize and parallelize well, and require little or no memory for state. We introduce several counter-based PRNGs: some based on cryptographic standards (AES, Threefish) and some completely new (Philox). All our PRNGs pass rigorous statistical tests (including TestU01's BigCrush) and produce at least 264 unique parallel streams of random numbers, each with period 2128 or more. In addition to essentially unlimited parallel scalability, our PRNGs offer excellent single-chip performance: Philox is faster than the CURAND library on a single NVIDIA GPU.},
    urldate = {2025-07-09},
    booktitle = {Proceedings of 2011 {International} {Conference} for {High} {Performance} {Computing}, {Networking}, {Storage} and {Analysis}},
    publisher = {Association for Computing Machinery},
    author = {Salmon, John K. and Moraes, Mark A. and Dror, Ron O. and Shaw, David E.},
    month = nov,
    year = {2011},
    pages = {1--12},
}

@inproceedings{stites_learning_2021,
    title = {Learning proposals for probabilistic programs with inference combinators},
    url = {https://proceedings.mlr.press/v161/stites21a.html},
    abstract = {We develop operators for construction of proposals in probabilistic programs, which we refer to as inference combinators. Inference combinators define a grammar over importance samplers that compose primitive operations such as application of a transition kernel and importance resampling. Proposals in these samplers can be parameterized using neural networks, which in turn can be trained by optimizing variational objectives. The result is a framework for user-programmable variational methods that are correct by construction and can be tailored to specific models. We demonstrate the flexibility of this framework by implementing advanced variational methods based on amortized Gibbs sampling and annealing.},
    language = {en},
    urldate = {2025-07-10},
    booktitle = {Proceedings of the {Thirty}-{Seventh} {Conference} on {Uncertainty} in {Artificial} {Intelligence}},
    publisher = {PMLR},
    address = {Virtual},
    author = {Stites, Sam and Zimmermann, Heiko and Wu, Hao and Sennesh, Eli and Meent, Jan-Willem van de},
    month = dec,
    year = {2021},
    note = {ISSN: 2640-3498},
    pages = {1056--1066},
    doi = {10.48550/arXiv.2103.00668},
}

@inproceedings{zhi-xuan_online_2020,
    title = {Online {Bayesian} {Goal} {Inference} for {Boundedly} {Rational} {Planning} {Agents}},
    volume = {33},
    url = {https://proceedings.neurips.cc/paper/2020/hash/df3aebc649f9e3b674eeb790a4da224e-Abstract.html},
    abstract = {People routinely infer the goals of others by observing their actions over time. Remarkably, we can do so even when those actions lead to failure, enabling us to assist others when we detect that they might not achieve their goals. How might we endow machines with similar capabilities? Here we present an architecture capable of inferring an agent’s goals online from both optimal and non-optimal sequences of actions. Our architecture models agents as boundedly-rational planners that interleave search with execution by replanning, thereby accounting for sub-optimal behavior. These models are specified as probabilistic programs, allowing us to represent and perform efficient Bayesian inference over an agent's goals and internal planning processes. To perform such inference, we develop Sequential Inverse Plan Search (SIPS), a sequential Monte Carlo algorithm that exploits the online replanning assumption of these models, limiting computation by incrementally extending inferred plans as new actions are observed. We present experiments showing that this modeling and inference architecture outperforms Bayesian inverse reinforcement learning baselines, accurately inferring goals from both optimal and non-optimal trajectories involving failure and back-tracking, while generalizing across domains with compositional structure and sparse rewards.},
    urldate = {2025-07-10},
    booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
    publisher = {Curran Associates, Inc.},
    address = {Virtual},
    author = {Zhi-Xuan, Tan and Mann, Jordyn and Silver, Tom and Tenenbaum, Josh and Mansinghka, Vikash},
    year = {2020},
    pages = {19238--19250},
    doi = {10.48550/arXiv.2006.07532},
}

@article{alanqary_modeling_2021,
    title = {Modeling the {Mistakes} of {Boundedly} {Rational} {Agents} {Within} a {Bayesian} {Theory} of {Mind}},
    volume = {43},
    url = {https://escholarship.org/uc/item/7tr2w3c9},
    abstract = {When inferring the goals that others are trying to achieve, people intuitively understand that others might make mistakes along the way. This is crucial for activities such as teaching, offering assistance, and deciding between blame or forgiveness. However, Bayesian models of theory of mind have generally not accounted for these mistakes, instead modeling agents as mostly optimal in achieving their goals. As a result, they are unable to explain phenomena like locking oneself out of one's house, or losing a game of chess. Here, we extend the Bayesian Theory of Mind framework to model boundedly rational agents who may have mistaken goals, plans, and actions. We formalize this by modeling agents as probabilistic programs, where goals may be confused with semantically similar states, plans may be misguided due to resource-bounded planning, and actions may be unintended due to execution errors. We present experiments eliciting human goal inferences in two domains: (i) a gridworld puzzle with gems locked behind doors, and (ii) a block-stacking domain. Our model better explains human inferences than alternatives, while generalizing across domains. These findings indicate the importance of modeling others as bounded agents, in order to account for the full richness of human intuitive psychology.},
    language = {en},
    number = {43},
    urldate = {2025-07-10},
    journal = {Proceedings of the Annual Meeting of the Cognitive Science Society},
    author = {Alanqary, Alwa and Lin, Gloria Z. and Le, Joie and Zhi-Xuan, Tan and Mansinghka, Vikash and Tenenbaum, Josh},
    year = {2021},

    doi = {10.48550/arXiv.2106.13249}
}

@misc{ying_grounding_2024,
    title = {Grounding {Language} about {Belief} in a {Bayesian} {Theory}-of-{Mind}},
    url = {http://arxiv.org/abs/2402.10416},
    doi = {10.48550/arXiv.2402.10416},
    abstract = {Despite the fact that beliefs are mental states that cannot be directly observed, humans talk about each others' beliefs on a regular basis, often using rich compositional language to describe what others think and know. What explains this capacity to interpret the hidden epistemic content of other minds? In this paper, we take a step towards an answer by grounding the semantics of belief statements in a Bayesian theory-of-mind: By modeling how humans jointly infer coherent sets of goals, beliefs, and plans that explain an agent's actions, then evaluating statements about the agent's beliefs against these inferences via epistemic logic, our framework provides a conceptual role semantics for belief, explaining the gradedness and compositionality of human belief attributions, as well as their intimate connection with goals and plans. We evaluate this framework by studying how humans attribute goals and beliefs while watching an agent solve a doors-and-keys gridworld puzzle that requires instrumental reasoning about hidden objects. In contrast to pure logical deduction, non-mentalizing baselines, and mentalizing that ignores the role of instrumental plans, our model provides a much better fit to human goal and belief attributions, demonstrating the importance of theory-of-mind for a semantics of belief.},
    urldate = {2025-07-10},
    publisher = {arXiv},
    author = {Ying, Lance and Zhi-Xuan, Tan and Wong, Lionel and Mansinghka, Vikash and Tenenbaum, Joshua},
    month = jul,
    year = {2024},
    note = {arXiv:2402.10416 [cs]},
    keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@misc{collins_building_2024,
    title = {Building {Machines} that {Learn} and {Think} with {People}},
    url = {http://arxiv.org/abs/2408.03943},
    doi = {10.48550/arXiv.2408.03943},
    abstract = {What do we want from machine intelligence? We envision machines that are not just tools for thought, but partners in thought: reasonable, insightful, knowledgeable, reliable, and trustworthy systems that think with us. Current artificial intelligence (AI) systems satisfy some of these criteria, some of the time. In this Perspective, we show how the science of collaborative cognition can be put to work to engineer systems that really can be called ``thought partners,'' systems built to meet our expectations and complement our limitations. We lay out several modes of collaborative thought in which humans and AI thought partners can engage and propose desiderata for human-compatible thought partnerships. Drawing on motifs from computational cognitive science, we motivate an alternative scaling path for the design of thought partners and ecosystems around their use through a Bayesian lens, whereby the partners we construct actively build and reason over models of the human and world.},
    urldate = {2025-07-10},
    publisher = {arXiv},
    author = {Collins, Katherine M. and Sucholutsky, Ilia and Bhatt, Umang and Chandra, Kartik and Wong, Lionel and Lee, Mina and Zhang, Cedegao E. and Zhi-Xuan, Tan and Ho, Mark and Mansinghka, Vikash and Weller, Adrian and Tenenbaum, Joshua B. and Griffiths, Thomas L.},
    month = jul,
    year = {2024},
    note = {arXiv:2408.03943 [cs]},
    keywords = {Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction, Computer Science - Machine Learning},
}

@inproceedings{DBLP:conf/rss/CurtisMG0TLK24,
  author       = {Aidan Curtis and George Matheos and Nishad Gothoskar and Vikash Mansinghka and Joshua B. Tenenbaum and Tom{\'{a}}s Lozano{-}P{\'{e}}rez and Leslie Pack Kaelbling},
  editor       = {Dana Kulic and Gentiane Venture and Kostas E. Bekris and Enrique Coronado},
  title        = {Partially Observable Task and Motion Planning with Uncertainty and Risk Awareness},
  booktitle    = {Robotics: Science and Systems XX, Delft, The Netherlands, July 15-19, 2024},
  publisher    = {Robotics: Science and Systems Foundation},
  address      = {Delft, The Netherlands},
  pages        = {118:1--118:9},
  year         = {2024},
  url          = {https://doi.org/10.15607/RSS.2024.XX.118},
  doi          = {10.15607/RSS.2024.XX.118},
  timestamp    = {Mon, 27 Jan 2025 10:48:05 +0100},
  biburl       = {https://dblp.org/rec/conf/rss/CurtisMG0TLK24.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{huot_gensql_2024,
    title = {{GenSQL}: {A} {Probabilistic} {Programming} {System} for {Querying} {Generative} {Models} of {Database} {Tables}},
    shorttitle = {{GenSQL}},
    journal = {Proc. {ACM} Program. Lang.},
    volume = {8},
    number = {{PLDI}},
    pages = {790--815},
    doi = {10.1145/3656409},
    url = {https://doi.org/10.1145/3656409},
    author = {Huot, Mathieu and Ghavami, Matin and Lew, Alexander K. and Schaechtle, Ulrich and Freer, Cameron E. and Shelby, Zane and Rinard, Martin C. and Saad, Feras A. and Mansinghka, Vikash K.},
    month = jun,
    year = {2024}
}

@article{saad_bayesian_2019,
    title = {Bayesian synthesis of probabilistic programs for automatic data modeling},
    journal = {Proc. {ACM} Program. Lang.},
    volume = {3},
    number = {{POPL}},
    pages = {37:1--37:32},
    doi = {10.1145/3290350},
    url = {https://doi.org/10.1145/3290350},
    author = {Saad, Feras A. and Cusumano-Towner, Marco F. and Schaechtle, Ulrich and Rinard, Martin C. and Mansinghka, Vikash K.},
    month = jan,
    year = {2019}
}

@article{loula_syntactic_2024,
  author       = {Jo{\~{a}}o Loula and Benjamin LeBrun and Li Du and Ben Lipkin and Clemente Pasti and Gabriel Grand and Tianyu Liu and Yahya Emara and Marjorie Freedman and Jason Eisner and Ryan Cotterell and Vikash Mansinghka and Alexander K. Lew and Tim Vieira and Timothy J. O'Donnell},
  title        = {Syntactic and Semantic Control of Large Language Models via Sequential Monte Carlo},
  journal      = {CoRR},
  volume       = {abs/2504.13139},
  year         = {2025},
  url          = {https://arxiv.org/abs/2504.13139},
  eprinttype    = {arXiv},
  eprint       = {2504.13139}
}

@misc{lipkin_fast_2025,
    title = {Fast {Controlled} {Generation} from {Language} {Models} with {Adaptive} {Weighted} {Rejection} {Sampling}},
    url = {http://arxiv.org/abs/2504.05410},
    doi = {10.48550/arXiv.2504.05410},
    abstract = {The dominant approach to generating from language models subject to some constraint is locally constrained decoding (LCD), incrementally sampling tokens at each time step such that the constraint is never violated. Typically, this is achieved through token masking: looping over the vocabulary and excluding non-conforming tokens. There are two important problems with this approach. (i) Evaluating the constraint on every token can be prohibitively expensive -- LM vocabularies often exceed \$100,000\$ tokens. (ii) LCD can distort the global distribution over strings, sampling tokens based only on local information, even if they lead down dead-end paths. This work introduces a new algorithm that addresses both these problems. First, to avoid evaluating a constraint on the full vocabulary at each step of generation, we propose an adaptive rejection sampling algorithm that typically requires orders of magnitude fewer constraint evaluations. Second, we show how this algorithm can be extended to produce low-variance, unbiased estimates of importance weights at a very small additional cost -- estimates that can be soundly used within previously proposed sequential Monte Carlo algorithms to correct for the myopic behavior of local constraint enforcement. Through extensive empirical evaluation in text-to-SQL, molecular synthesis, goal inference, pattern matching, and JSON domains, we show that our approach is superior to state-of-the-art baselines, supporting a broader class of constraints and improving both runtime and performance. Additional theoretical and empirical analyses show that our method's runtime efficiency is driven by its dynamic use of computation, scaling with the divergence between the unconstrained and constrained LM, and as a consequence, runtime improvements are greater for better models.},
    urldate = {2025-07-10},
    journal = {CoRR},
    volume = {abs/2504.05410},
    publisher = {arXiv},
    author = {Lipkin, Benjamin and LeBrun, Benjamin and Vigly, Jacob Hoover and Loula, João and MacIver, David R. and Du, Li and Eisner, Jason and Cotterell, Ryan and Mansinghka, Vikash and O'Donnell, Timothy J. and Lew, Alexander K. and Vieira, Tim},
    month = apr,
    year = {2025},
    note = {arXiv:2504.05410 [cs]},
    keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@article{cusumano-towner_aide_2017,
    title = {{AIDE}: {An} algorithm for measuring the accuracy of probabilistic inference algorithms},
    shorttitle = {{AIDE}},
    url = {http://arxiv.org/abs/1705.07224},
    abstract = {Approximate probabilistic inference algorithms are central to many fields. Examples include sequential Monte Carlo inference in robotics, variational inference in machine learning, and Markov chain Monte Carlo inference in statistics. A key problem faced by practitioners is measuring the accuracy of an approximate inference algorithm on a specific data set. This paper introduces the auxiliary inference divergence estimator (AIDE), an algorithm for measuring the accuracy of approximate inference algorithms. AIDE is based on the observation that inference algorithms can be treated as probabilistic models and the random variables used within the inference algorithm can be viewed as auxiliary variables. This view leads to a new estimator for the symmetric KL divergence between the approximating distributions of two inference algorithms. The paper illustrates application of AIDE to algorithms for inference in regression, hidden Markov, and Dirichlet process mixture models. The experiments show that AIDE captures the qualitative behavior of a broad class of inference algorithms and can detect failure modes of inference algorithms that are missed by standard heuristics.},
    urldate = {2022-04-19},
    journal = {CoRR},
    volume = {abs/1705.07224},
    author = {Cusumano-Towner, Marco F. and Mansinghka, Vikash K.},
    month = nov,
    year = {2017},
    eprint = {1705.07224},
    doi = {10.48550/arXiv.1705.07224},
    archivePrefix = {arXiv},
    primaryClass = {cs.AI},
    keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},

}

@article{saad_estimators_2022,
    title = {Estimators of {Entropy} and {Information} via {Inference} in {Probabilistic} {Models}},
    url = {http://arxiv.org/abs/2202.12363},
    abstract = {Estimating information-theoretic quantities such as entropy and mutual information is central to many problems in statistics and machine learning, but challenging in high dimensions. This paper presents estimators of entropy via inference (EEVI), which deliver upper and lower bounds on many information quantities for arbitrary variables in a probabilistic generative model. These estimators use importance sampling with proposal distribution families that include amortized variational inference and sequential Monte Carlo, which can be tailored to the target model and used to squeeze true information values with high accuracy. We present several theoretical properties of EEVI and demonstrate scalability and efficacy on two problems from the medical domain: (i) in an expert system for diagnosing liver disorders, we rank medical tests according to how informative they are about latent diseases, given a pattern of observed symptoms and patient attributes; and (ii) in a differential equation model of carbohydrate metabolism, we find optimal times to take blood glucose measurements that maximize information about a diabetic patient's insulin sensitivity, given their meal and medication schedule.},
    urldate = {2022-04-20},
    journal = {CoRR},
    volume = {abs/2202.12363},
    author = {Saad, Feras A. and Cusumano-Towner, Marco and Mansinghka, Vikash K.},
    month = apr,
    year = {2022},
    eprint = {2202.12363},
    doi = {10.48550/arXiv.2202.12363},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    keywords = {Computer Science - Machine Learning, Statistics - Computation, Statistics - Machine Learning, Statistics - Methodology},

}

@article{domke_easy_2021,
    title = {An {Easy} to {Interpret} {Diagnostic} for {Approximate} {Inference}: {Symmetric} {Divergence} {Over} {Simulations}},
    shorttitle = {An {Easy} to {Interpret} {Diagnostic} for {Approximate} {Inference}},
    url = {https://arxiv.org/abs/2103.01030v1},
    doi = {10.48550/arXiv.2103.01030},
    abstract = {It is important to estimate the errors of probabilistic inference algorithms. Existing diagnostics for Markov chain Monte Carlo methods assume inference is asymptotically exact, and are not appropriate for approximate methods like variational inference or Laplace's method. This paper introduces a diagnostic based on repeatedly simulating datasets from the prior and performing inference on each. The central observation is that it is possible to estimate a symmetric KL-divergence defined over these simulations.},
    language = {en},
    urldate = {2022-05-02},
    journal = {CoRR},
    volume = {abs/2103.01030},
    author = {Domke, Justin},
    month = feb,
    year = {2021},

}

@article{saad_family_2019,
    title = {A {Family} of {Exact} {Goodness}-of-{Fit} {Tests} for {High}-{Dimensional} {Discrete} {Distributions}},
    url = {http://arxiv.org/abs/1902.10142},
    abstract = {The objective of goodness-of-fit testing is to assess whether a dataset of observations is likely to have been drawn from a candidate probability distribution. This paper presents a rank-based family of goodness-of-fit tests that is specialized to discrete distributions on high-dimensional domains. The test is readily implemented using a simulation-based, linear-time procedure. The testing procedure can be customized by the practitioner using knowledge of the underlying data domain. Unlike most existing test statistics, the proposed test statistic is distribution-free and its exact (non-asymptotic) sampling distribution is known in closed form. We establish consistency of the test against all alternatives by showing that the test statistic is distributed as a discrete uniform if and only if the samples were drawn from the candidate distribution. We illustrate its efficacy for assessing the sample quality of approximate sampling algorithms over combinatorially large spaces with intractable probabilities, including random partitions in Dirichlet process mixture models and random lattices in Ising models.},
    urldate = {2022-04-19},
    journal = {CoRR},
    volume = {abs/1902.10142},
    author = {Saad, Feras A. and Freer, Cameron E. and Ackerman, Nathanael L. and Mansinghka, Vikash K.},
    month = feb,
    year = {2019},
    eprint = {1902.10142},
    doi = {10.48550/arXiv.1902.10142},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},
    keywords = {Computer Science - Machine Learning, Mathematics - Statistics Theory, Statistics - Methodology},

}
% Explicitly discusses tape-based implementations

@inproceedings{wingate_lightweight_2011,
    title = {Lightweight {Implementations} of {Probabilistic} {Programming} {Languages} {Via} {Transformational} {Compilation}},
    url = {https://proceedings.mlr.press/v15/wingate11a.html},
    abstract = {We describe a general method of transforming arbitrary programming languages into probabilistic programming languages with straightforward MCMC inference engines.  Random choices in the program are “named” with information about their position in an execution trace; these names are used in conjunction with a database of randomness to implement MCMC inference in the space of execution traces.  We encode naming information using lightweight source-to-source compilers.  Our method enables us to reuse existing infrastructure (compilers, interpreters, etc.) with minimal additional code, implying fast models with low development overhead.  We illustrate the technique on two languages, one functional and one imperative: Bher, a compiled version of the Church language which eliminates interpretive overhead of the original MIT-Church implementation, and Stochastic Matlab, a new open-source language.},
    language = {en},
    urldate = {2025-07-10},
    booktitle = {Proceedings of the {Fourteenth} {International} {Conference} on {Artificial} {Intelligence} and {Statistics}},
    publisher = {JMLR Workshop and Conference Proceedings},
    address = {Fort Lauderdale, FL, USA},
    author = {Wingate, David and Stuhlmueller, Andreas and Goodman, Noah},
    month = jun,
    year = {2011},
    note = {ISSN: 1938-7228},
    pages = {770--778},
}

@book{DBLP:books/mit/AbelsonS96,
  author       = {Harold Abelson and Gerald J. Sussman},
  title        = {Structure and Interpretation of Computer Programs, Second Edition},
  publisher    = {{MIT} Press},
  address      = {Cambridge, MA, USA},
  year         = {1996},
  isbn         = {0-262-01153-0},
  timestamp    = {Mon, 28 Jan 2002 16:12:01 +0100},
  biburl       = {https://dblp.org/rec/books/mit/AbelsonS96.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@book{doucet_sequential_2001,
    address = {New York},
    series = {Information {Science} and {Statistics}},
    title = {Sequential {Monte} {Carlo} {Methods} in {Practice}},
    isbn = {978-0-387-95146-1},
    url = {https://www.springer.com/gp/book/9780387951461},
    abstract = {Monte Carlo methods are revolutionising the on-line analysis of data in fields as diverse as financial modelling, target tracking and computer vision. These methods, appearing under the names of bootstrap filters, condensation, optimal Monte Carlo filters, particle filters and survial of the fittest, have made it possible to solve numerically many complex, non-standarard problems that were previously intractable. This book presents the first comprehensive treatment of these techniques, including convergence results and applications to tracking, guidance, automated target recognition, aircraft navigation, robot navigation, econometrics, financial modelling, neural networks,optimal control, optimal filtering, communications, reinforcement learning, signal enhancement, model averaging and selection, computer vision, semiconductor design, population biology, dynamic Bayesian networks, and time series analysis. This will be of great value to students, researchers and practicioners, who have some basic knowledge of probability. Arnaud Doucet received the Ph. D. degree from the University of Paris- XI Orsay in 1997. From 1998 to 2000, he conducted research at the Signal Processing Group of Cambridge University, UK. He is currently an assistant professor at the Department of Electrical Engineering of Melbourne University, Australia. His research interests include Bayesian statistics, dynamic models and Monte Carlo methods. Nando de Freitas obtained a Ph.D. degree in information engineering from Cambridge University in 1999. He is presently a research associate with the artificial intelligence group of the University of California at Berkeley. His main research interests are in Bayesian statistics and the application of on-line and batch Monte Carlo methods to machine learning.},
    language = {en},
    urldate = {2020-01-10},
    publisher = {Springer-Verlag},
    editor = {Doucet, Arnaud and de Freitas, Nando and Gordon, Neil},
    year = {2001},
    doi = {10.1007/978-1-4757-3437-9},
}

@article{del_moral_sequential_2006,
    title = {Sequential {Monte} {Carlo} samplers},
    volume = {68},
    issn = {1369-7412, 1467-9868},
    url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1467-9868.2006.00553.x},
    doi = {10.1111/j.1467-9868.2006.00553.x},
    abstract = {We propose a methodology to sample sequentially from a sequence of probability distributions that are deﬁned on a common space, each distribution being known up to a normalizing constant. These probability distributions are approximated by a cloud of weighted random samples which are propagated over time by using sequential Monte Carlo methods. This methodology allows us to derive simple algorithms to make parallel Markov chain Monte Carlo algorithms interact to perform global optimization and sequential Bayesian estimation and to compute ratios of normalizing constants. We illustrate these algorithms for various integration tasks arising in the context of Bayesian inference.},
    language = {en},
    number = {3},
    urldate = {2022-04-21},
    journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
    author = {Del Moral, Pierre and Doucet, Arnaud and Jasra, Ajay},
    month = jun,
    year = {2006},
    pages = {411--436},
}

@inproceedings{baydin_etalumis_2019,
    address = {New York, NY, USA},
    series = {{SC} '19},
    title = {Etalumis: bringing probabilistic programming to scientific simulators at scale},
    isbn = {978-1-4503-6229-0},
    shorttitle = {Etalumis},
    url = {https://dl.acm.org/doi/10.1145/3295500.3356180},
    doi = {10.1145/3295500.3356180},
    abstract = {Probabilistic programming languages (PPLs) are receiving widespread attention for performing Bayesian inference in complex generative models. However, applications to science remain limited because of the impracticability of rewriting complex scientific simulators in a PPL, the computational cost of inference, and the lack of scalable implementations. To address these, we present a novel PPL framework that couples directly to existing scientific simulators through a cross-platform probabilistic execution protocol and provides Markov chain Monte Carlo (MCMC) and deep-learning-based inference compilation (IC) engines for tractable inference. To guide IC inference, we perform distributed training of a dynamic 3DCNN-LSTM architecture with a PyTorch-MPI-based framework on 1,024 32-core CPU nodes of the Cori supercomputer with a global mini-batch size of 128k: achieving a performance of 450 Tflop/s through enhancements to PyTorch. We demonstrate a Large Hadron Collider (LHC) use-case with the C++ Sherpa simulator and achieve the largest-scale posterior inference in a Turing-complete PPL.},
    urldate = {2025-07-10},
    booktitle = {Proceedings of the {International} {Conference} for {High} {Performance} {Computing}, {Networking}, {Storage} and {Analysis}},
    publisher = {Association for Computing Machinery},
    author = {Baydin, Atilim Güneş and Shao, Lei and Bhimji, Wahid and Heinrich, Lukas and Meadows, Lawrence and Liu, Jialin and Munk, Andreas and Naderiparizi, Saeid and Gram-Hansen, Bradley and Louppe, Gilles and Ma, Mingfei and Zhao, Xiaohui and Torr, Philip and Lee, Victor and Cranmer, Kyle and Prabhat and Wood, Frank},
    month = nov,
    year = {2019},
    pages = {1--24},
}

@article{salvatier_probabilistic_2016,
    title = {Probabilistic programming in {Python} using {PyMC3}},
    volume = {2},
    issn = {2376-5992},
    url = {https://peerj.com/articles/cs-55},
    doi = {10.7717/peerj-cs.55},
    abstract = {Probabilistic programming allows for automatic Bayesian inference on user-defined probabilistic models. Recent advances in Markov chain Monte Carlo (MCMC) sampling allow inference on increasingly complex models. This class of MCMC, known as Hamiltonian Monte Carlo, requires gradient information which is often not readily available. PyMC3 is a new open source probabilistic programming framework written in Python that uses Theano to compute gradients via automatic differentiation as well as compile probabilistic programs on-the-fly to C for increased speed. Contrary to other probabilistic programming languages, PyMC3 allows model specification directly in Python code. The lack of a domain specific language allows for great flexibility and direct interaction with the model. This paper is a tutorial-style introduction to this software package.},
    language = {en},
    urldate = {2025-07-11},
    journal = {PeerJ Computer Science},
    author = {Salvatier, John and Wiecki, Thomas V. and Fonnesbeck, Christopher},
    month = apr,
    year = {2016},
    note = {Publisher: PeerJ Inc.},
    pages = {e55},
}

@article{futamura_partial_1999,
    title = {Partial {Evaluation} of {Computation} {Process}, {Revisited}},
    volume = {12},
    issn = {1573-0557},
    url = {https://doi.org/10.1023/A:1010043619517},
    doi = {10.1023/A:1010043619517},
    language = {en},
    number = {4},
    urldate = {2025-07-11},
    journal = {Higher-Order and Symbolic Computation},
    author = {Futamura, Yoshihiko},
    month = dec,
    year = {1999},
    keywords = {Artificial Intelligence, Operating System, Partial Evaluation},
    pages = {377--380},
}

@inproceedings{marr_tracing_2015,
    address = {New York, NY, USA},
    series = {{OOPSLA} 2015},
    title = {Tracing vs. partial evaluation: comparing meta-compilation approaches for self-optimizing interpreters},
    isbn = {978-1-4503-3689-5},
    shorttitle = {Tracing vs. partial evaluation},
    url = {https://doi.org/10.1145/2814270.2814275},
    doi = {10.1145/2814270.2814275},
    abstract = {Tracing and partial evaluation have been proposed as meta-compilation techniques for interpreters to make just-in-time compilation language-independent. They promise that programs executing on simple interpreters can reach performance of the same order of magnitude as if they would be executed on state-of-the-art virtual machines with highly optimizing just-in-time compilers built for a specific language. Tracing and partial evaluation approach this meta-compilation from two ends of a spectrum, resulting in different sets of tradeoffs. This study investigates both approaches in the context of self-optimizing interpreters, a technique for building fast abstract-syntax-tree interpreters. Based on RPython for tracing and Truffle for partial evaluation, we assess the two approaches by comparing the impact of various optimizations on the performance of an interpreter for SOM, an object-oriented dynamically-typed language. The goal is to determine whether either approach yields clear performance or engineering benefits. We find that tracing and partial evaluation both reach roughly the same level of performance. SOM based on meta-tracing is on average 3x slower than Java, while SOM based on partial evaluation is on average 2.3x slower than Java. With respect to the engineering, tracing has however significant benefits, because it requires language implementers to apply fewer optimizations to reach the same level of performance.},
    urldate = {2025-07-10},
    booktitle = {Proceedings of the 2015 {ACM} {SIGPLAN} {International} {Conference} on {Object}-{Oriented} {Programming}, {Systems}, {Languages}, and {Applications}},
    publisher = {Association for Computing Machinery},
    author = {Marr, Stefan and Ducasse, Stéphane},
    month = oct,
    year = {2015},
    pages = {821--839},
}

@article{jones_introduction_1996,
    title = {An introduction to partial evaluation},
    volume = {28},
    issn = {0360-0300, 1557-7341},
    url = {https://dl.acm.org/doi/10.1145/243439.243447},
    doi = {10.1145/243439.243447},
    abstract = {Partial evaluation provides a unifying paradigm for a broad spectrum of work in program optimization compiling interpretation and the generation of automatic program generators [Bjørner et al. 1987; Ershov 1992; and Jones et al. 1993]. It is a program optimization technique, perhaps better called
              program specialization
              , closely related to but different from Jørring and Scherlis'
              staging transformations
              [1986]. It emphasizes, in comparison with Burstall and Darlington [1977] and Jørring and Scherlis [1986] and other program transformation work,
              full automation
              and the generation of
              program generators
              as well as transforming single programs. Much partial evaluation work to date has concerned automatic compiler generation from an interpretive definition of programming language, but it also has important applications to scientific computing, logic programming, metaprogramming, and expert systems; some pointers are given later.},
    language = {en},
    number = {3},
    urldate = {2021-12-08},
    journal = {ACM Computing Surveys},
    author = {Jones, Neil D.},
    month = sep,
    year = {1996},
    pages = {480--503},
}

@article{dempster_maximum_1977,
    title = {Maximum {Likelihood} from {Incomplete} {Data} {Via} the {EM} {Algorithm}},
    volume = {39},
    issn = {0035-9246},
    url = {https://doi.org/10.1111/j.2517-6161.1977.tb01600.x},
    doi = {10.1111/j.2517-6161.1977.tb01600.x},
    abstract = {A broadly applicable algorithm for computing maximum likelihood estimates from incomplete data is presented at various levels of generality. Theory showing the monotone behaviour of the likelihood and convergence of the algorithm is derived. Many examples are sketched, including missing value situations, applications to grouped, censored or truncated data, finite mixture models, variance component estimation, hyperparameter estimation, iteratively reweighted least squares and factor analysis.},
    number = {1},
    urldate = {2025-07-11},
    journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
    author = {Dempster, A. P. and Laird, N. M. and Rubin, D. B.},
    month = sep,
    year = {1977},
    pages = {1--22},
}

@inproceedings{linderman_bayesian_2017,
    title = {Bayesian {Learning} and {Inference} in {Recurrent} {Switching} {Linear} {Dynamical} {Systems}},
    url = {https://proceedings.mlr.press/v54/linderman17a.html},
    abstract = {Many natural systems, such as neurons firing in the brain or basketball teams traversing a court, give rise to time series data with complex, nonlinear dynamics.  We can gain insight into these systems by decomposing the data into segments that are each explained by simpler dynamic units. Building on switching linear dynamical systems (SLDS), we develop a model class and Bayesian inference algorithms that not only discover these dynamical units but also, by learning how transition probabilities depend on observations or continuous latent states, explain their switching behavior.  Our key innovation is to design these recurrent SLDS models to enable recent Pólya-gamma auxiliary variable techniques and thus make approximate Bayesian learning and inference in these models easy, fast, and scalable.},
    language = {en},
    urldate = {2025-07-11},
    booktitle = {Proceedings of the 20th {International} {Conference} on {Artificial} {Intelligence} and {Statistics}},
    publisher = {PMLR},
    address = {Fort Lauderdale, FL, USA},
    author = {Linderman, Scott and Johnson, Matthew and Miller, Andrew and Adams, Ryan and Blei, David and Paninski, Liam},
    month = apr,
    year = {2017},
    note = {ISSN: 2640-3498},
    pages = {914--922},
}

@article{fine_hierarchical_1998,
    title = {The {Hierarchical} {Hidden} {Markov} {Model}: {Analysis} and {Applications}},
    volume = {32},
    issn = {1573-0565},
    shorttitle = {The {Hierarchical} {Hidden} {Markov} {Model}},
    url = {https://doi.org/10.1023/A:1007469218079},
    doi = {10.1023/A:1007469218079},
    abstract = {We introduce, analyze and demonstrate a recursive hierarchical generalization of the widely used hidden Markov models, which we name Hierarchical Hidden Markov Models (HHMM). Our model is motivated by the complex multi-scale structure which appears in many natural sequences, particularly in language, handwriting and speech. We seek a systematic unsupervised approach to the modeling of such structures. By extending the standard Baum-Welch (forward-backward) algorithm, we derive an efficient procedure for estimating the model parameters from unlabeled data. We then use the trained model for automatic hierarchical parsing of observation sequences. We describe two applications of our model and its parameter estimation procedure. In the first application we show how to construct hierarchical models of natural English text. In these models different levels of the hierarchy correspond to structures on different length scales in the text. In the second application we demonstrate how HHMMs can be used to automatically identify repeated strokes that represent combination of letters in cursive handwriting.},
    language = {en},
    number = {1},
    urldate = {2025-07-11},
    journal = {Machine Learning},
    author = {Fine, Shai and Singer, Yoram and Tishby, Naftali},
    month = jul,
    year = {1998},
    keywords = {Computational Linguistics, Information Model, Machine Learning, Markov Process, Stochastic Modelling, Stochastic Modelling in Statistics, cursive handwriting, hidden variable models, statistical models, temporal pattern recognition},
    pages = {41--62},
}

@article{kim_dynamic_1994,
    title = {Dynamic linear models with {Markov}-switching},
    volume = {60},
    issn = {0304-4076},
    url = {https://www.sciencedirect.com/science/article/pii/0304407694900361},
    doi = {10.1016/0304-4076(94)90036-1},
    abstract = {In this paper, Hamilton's (1988, 1989) Markov-switching model is extended to a general state-space model. This paper also complements Shumway and Stoffer's (1991) dynamic linear models with switching, by introducing dependence in the switching process, and by allowing switching in both measurement and transition equations. Building upon ideas in Hamilton (1989), Cosslett and Lee (1985), and Harrison and Stevens (1976), a basic filtering and smoothing algorithm is presented. The algorithm and the maximum likelihood estimation procedure is applied in estimating Lam's (1990) generalized Hamilton model with a general autoregressive component. The estimation results show that the approximation employed in this paper performs an excellent job, with a considerable advantage in computation time. A state–space representation is a very flexible form, and the approach taken in this paper therefore allows a broad class of models to be estimated that could not be handled before. In addition, the algorithm for calculating smoothed inferences on the unobserved states is a vastly more efficient one than that in the literature.},
    number = {1},
    urldate = {2025-07-11},
    journal = {Journal of Econometrics},
    author = {Kim, Chang-Jin},
    month = jan,
    year = {1994},
    keywords = {Basic filtering, Generalized Hamilton model, Markov-switching, Smoothing, State-space model},
    pages = {1--22},
}

@article{cappe_adaptive_2008,
    title = {Adaptive importance sampling in general mixture classes},
    volume = {18},
    issn = {1573-1375},
    url = {https://doi.org/10.1007/s11222-008-9059-x},
    doi = {10.1007/s11222-008-9059-x},
    abstract = {In this paper, we propose an adaptive algorithm that iteratively updates both the weights and component parameters of a mixture importance sampling density so as to optimise the performance of importance sampling, as measured by an entropy criterion. The method, called M-PMC, is shown to be applicable to a wide class of importance sampling densities, which includes in particular mixtures of multivariate Student t distributions. The performance of the proposed scheme is studied on both artificial and real examples, highlighting in particular the benefit of a novel Rao-Blackwellisation device which can be easily incorporated in the updating scheme.},
    language = {en},
    number = {4},
    urldate = {2025-07-11},
    journal = {Statistics and Computing},
    author = {Cappé, Olivier and Douc, Randal and Guillin, Arnaud and Marin, Jean-Michel and Robert, Christian P.},
    month = dec,
    year = {2008},
    keywords = {Adaptive Monte Carlo, Applied Probability, Applied Statistics, EM algorithm, Entropy, Importance sampling, Kullback-Leibler divergence, Mixture model, Population Monte Carlo, Probability and Statistics in Computer Science, Statistical Theory and Methods, Statistics in Engineering, Physics, Computer Science, Chemistry and Earth Sciences, Stochastic Learning and Adaptive Control},
    pages = {447--459},
}

@article{bugallo_adaptive_2017,
    title = {Adaptive {Importance} {Sampling}: {The} past, the present, and the future},
    volume = {34},
    issn = {1558-0792},
    shorttitle = {Adaptive {Importance} {Sampling}},
    url = {https://ieeexplore.ieee.org/document/7974876},
    doi = {10.1109/MSP.2017.2699226},
    abstract = {A fundamental problem in signal processing is the estimation of unknown parameters or functions from noisy observations. Important examples include localization of objects in wireless sensor networks [1] and the Internet of Things [2]; multiple source reconstruction from electroencephalograms [3]; estimation of power spectral density for speech enhancement [4]; or inference in genomic signal processing [5]. Within the Bayesian signal processing framework, these problems are addressed by constructing posterior probability distributions of the unknowns. The posteriors combine optimally all of the information about the unknowns in the observations with the information that is present in their prior probability distributions. Given the posterior, one often wants to make inference about the unknowns, e.g., if we are estimating parameters, finding the values that maximize their posterior or the values that minimize some cost function given the uncertainty of the parameters. Unfortunately, obtaining closed-form solutions to these types of problems is infeasible in most practical applications, and therefore, developing approximate inference techniques is of utmost interest.},
    number = {4},
    urldate = {2025-07-11},
    journal = {IEEE Signal Processing Magazine},
    author = {Bugallo, Monica F. and Elvira, Victor and Martino, Luca and Luengo, David and Miguez, Joaquin and Djuric, Petar M.},
    month = jul,
    year = {2017},
    keywords = {Artificial intelligence, Bayes methods, Monte Carlo methods, Probability distribution, Sampling methods, Signal processing, Signal processing algorithms},
    pages = {60--79},
}

@inproceedings{murphy_linear-time_2001,
  author       = {Kevin P. Murphy and Mark A. Paskin},
  editor       = {Thomas G. Dietterich and Suzanna Becker and Zoubin Ghahramani},
  title        = {Linear-time inference in Hierarchical {HMMs}},
  booktitle    = {Advances in Neural Information Processing Systems 14: {NIPS} 2001, December 3-8, 2001, Vancouver, British Columbia, Canada},
  pages        = {833--840},
  publisher    = {{MIT} Press},
  address      = {Vancouver, BC, Canada},
  year         = {2001},
  url          = {https://proceedings.neurips.cc/paper/2001/hash/aebf7782a3d445f43cf30ee2c0d84dee-Abstract.html},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{gilks_following_2001,
    title = {Following a {Moving} {Target}-{Monte} {Carlo} {Inference} for {Dynamic} {Bayesian} {Models}},
    volume = {63},
    issn = {1369-7412},
    url = {https://www.jstor.org/stable/2680638},
    abstract = {Markov chain Monte Carlo (MCMC) sampling is a numerically intensive simulation technique which has greatly improved the practicality of Bayesian inference and prediction. However, MCMC sampling is too slow to be of practical use in problems involving a large number of posterior (target) distributions, as in dynamic modelling and predictive model selection. Alternative simulation techniques for tracking moving target distributions, known as particle filters, which combine importance sampling, importance resampling and MCMC sampling, tend to suffer from a progressive degeneration as the target sequence evolves. We propose a new technique, based on these same simulation methodologies, which does not suffer from this progressive degeneration.},
    number = {1},
    urldate = {2025-07-11},
    journal = {Journal of the Royal Statistical Society. Series B (Statistical Methodology)},
    author = {Gilks, Walter R. and Berzuini, Carlo},
    year = {2001},
    note = {Publisher: [Royal Statistical Society, Oxford University Press]},
    pages = {127--146},
}

@article{hastings_monte_1970,
    title = {Monte {Carlo} {Sampling} {Methods} {Using} {Markov} {Chains} and {Their} {Applications}},
    volume = {57},
    issn = {0006-3444},
    url = {https://www.jstor.org/stable/2334940},
    doi = {10.2307/2334940},
    abstract = {A generalization of the sampling method introduced by Metropolis et al. (1953) is presented along with an exposition of the relevant theory, techniques of application and methods and difficulties of assessing the error in Monte Carlo estimates. Examples of the methods, including the generation of random orthogonal matrices and potential applications of the methods to numerical problems arising in statistics, are discussed.},
    number = {1},
    urldate = {2025-07-11},
    journal = {Biometrika},
    author = {Hastings, W. K.},
    year = {1970},
    note = {Publisher: [Oxford University Press, Biometrika Trust]},
    pages = {97--109},
}

@article{tierney_markov_1994,
    title = {Markov {Chains} for {Exploring} {Posterior} {Distributions}},
    volume = {22},
    issn = {0090-5364, 2168-8966},
    url = {https://projecteuclid.org/journals/annals-of-statistics/volume-22/issue-4/Markov-Chains-for-Exploring-Posterior-Distributions/10.1214/aos/1176325750.full},
    doi = {10.1214/aos/1176325750},
    abstract = {Several Markov chain methods are available for sampling from a posterior distribution. Two important examples are the Gibbs sampler and the Metropolis algorithm. In addition, several strategies are available for constructing hybrid algorithms. This paper outlines some of the basic methods and strategies and discusses some related theoretical and practical issues. On the theoretical side, results from the theory of general state space Markov chains can be used to obtain convergence rates, laws of large numbers and central limit theorems for estimates obtained from Markov chain methods. These theoretical results can be used to guide the construction of more efficient algorithms. For the practical use of Markov chain methods, standard simulation methodology provides several variance reduction techniques and also give guidance on the choice of sample size and allocation.},
    number = {4},
    urldate = {2025-07-11},
    journal = {The Annals of Statistics},
    author = {Tierney, Luke},
    month = dec,
    year = {1994},
    note = {Publisher: Institute of Mathematical Statistics},
    keywords = {60J05, 62-04, 65C05, Gibbs sampler, Metropolis-Hastings algorithm, Monte Carlo, variance reduction},
    pages = {1701--1728},
}

@article{green_reversible_1995,
    title = {Reversible {Jump} {Markov} {Chain} {Monte} {Carlo} {Computation} and {Bayesian} {Model} {Determination}},
    volume = {82},
    issn = {0006-3444},
    url = {https://www.jstor.org/stable/2337340},
    doi = {10.2307/2337340},
    abstract = {Markov chain Monte Carlo methods for Bayesian computation have until recently been restricted to problems where the joint distribution of all variables has a density with respect to some fixed standard underlying measure. They have therefore not been available for application to Bayesian model determination, where the dimensionality of the parameter vector is typically not fixed. This paper proposes a new framework for the construction of reversible Markov chain samplers that jump between parameter subspaces of differing dimensionality, which is flexible and entirely constructive. It should therefore have wide applicability in model determination problems. The methodology is illustrated with applications to multiple change-point analysis in one and two dimensions, and to a Bayesian comparison of binomial experiments.},
    number = {4},
    urldate = {2025-07-11},
    journal = {Biometrika},
    author = {Green, Peter J.},
    year = {1995},
    note = {Publisher: [Oxford University Press, Biometrika Trust]},
    pages = {711--732},
}

@article{cusumano-towner_automating_2020,
    title = {Automating {Involutive} {MCMC} using {Probabilistic} and {Differentiable} {Programming}.},
    url = {http://arxiv.org/abs/2007.05436},
    abstract = {Involutive MCMC is a unifying mathematical construction for MCMC kernels that generalizes many classic and state-of-the-art MCMC algorithms, from reversible jump MCMC to kernels based on deep neural networks. But as with MCMC samplers more generally, implementing involutive MCMC kernels is often tedious and error-prone, especially when sampling on complex state spaces. This paper describes a technique for automating the implementation of involutive MCMC kernels given (i) a pair of probabilistic programs defining the target distribution and an auxiliary distribution respectively and (ii) a differentiable program that transforms the execution traces of these probabilistic programs. The technique, which is implemented as part of the Gen probabilistic programming system, also automatically detects user errors in the specification of involutive MCMC kernels and exploits sparsity in the kernels for improved efficiency. The paper shows example Gen code for a split-merge reversible jump move in an infinite Gaussian mixture model and a state-dependent mixture of proposals on a combinatorial space of covariance functions for a Gaussian process.},
    urldate = {2025-07-11},
    journal = {CoRR},
    volume = {abs/2007.05436},
    author = {Cusumano-Towner, Marco F. and Lew, Alexander K. and Mansinghka, Vikash K.},
    month = jul,
    year = {2020},
    eprint = {2007.05436},

    doi = {10.48550/arXiv.2007.05436},
    archivePrefix = {arXiv},
    primaryClass = {cs.LG},

}

@inproceedings{narayanan2016probabilistic,
	    title = {Probabilistic inference by program transformation in Hakaru (system description)},
	    author = {Narayanan, Praveen and Carette, Jacques and Romano, Wren and Shan, Chung{-}chieh and Zinkov, Robert},
	    booktitle = {International Symposium on Functional and Logic Programming - 13th International Symposium, {FLOPS} 2016, Kochi, Japan, March 4-6, 2016, Proceedings},
	    pages = {62--79},
	    year = {2016},
	    publisher = {Springer},
	    address = {Cham, Switzerland},
	    url = {http://dx.doi.org/10.1007/978-3-319-29604-3_5},
	    doi = {10.1007/978-3-319-29604-3_5},
	}
